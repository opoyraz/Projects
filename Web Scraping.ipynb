{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "  <head>\n",
    "    <title>Intro HTML</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <p>Hello World!</p>\n",
    "    <p>Enjoy DataCamp!</p>\n",
    "  </body>\n",
    "</html>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n  <head>\\n    <title>Website Title</title>\\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"style.css\">\\n  </head>\\n  <body>\\n    <div class=\"class1\" id=\"div1\">\\n      <p class=\"class2\">\\n        Visit <a href=\"http://datacamp.com/\">DataCamp</a>!\\n      </p>\\n    </div>\\n    <div class=\"class1 class3\" id=\"div2\">\\n      Hello World!\\n    </div>\\n  </body>\\n</html>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''<html>\n",
    "  <head>\n",
    "    <title>Website Title</title>\n",
    "    <link rel=\"stylesheet\" type=\"text/css\" href=\"style.css\">\n",
    "  </head>\n",
    "  <body>\n",
    "    <div class=\"class1\" id=\"div1\">\n",
    "      <p class=\"class2\">\n",
    "        Visit <a href=\"http://datacamp.com/\">DataCamp</a>!\n",
    "      </p>\n",
    "    </div>\n",
    "    <div class=\"class1 class3\" id=\"div2\">\n",
    "      Hello World!\n",
    "    </div>\n",
    "  </body>\n",
    "</html>'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n  <body>\\n    <div>\\n      <p>Good Luck!</p>\\n      <p>Not here...</p>\\n    </div>\\n    <div>\\n      <p>Where am I?</p>\\n    </div>\\n  </body>\\n</html>'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''<html>\n",
    "  <body>\n",
    "    <div>\n",
    "      <p>Good Luck!</p>\n",
    "      <p>Not here...</p>\n",
    "    </div>\n",
    "    <div>\n",
    "      <p>Where am I?</p>\n",
    "    </div>\n",
    "  </body>\n",
    "</html>'''\n",
    "\n",
    "xpath= '/html/body/div[2]p[1]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html='\\n<html>\\n<body>\\n<div>Div 1: <p>paragraph 1</p></div>\\n<div>Div 2: <p>paragraph 2</p> <p>paragraph 3</p> </div>\\n<div>Div 3: <p>paragraph 4</p> <p>paragraph 5</p> <p>paragraph 6</p></div>\\n<div>Div 4: <p>paragraph 7</p></div>\\n<div>Div 5: <p>paragraph 8</p></div>\\n</body>\\n</html>\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel=Selector(text=html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel.xpath('/html/body/div[2]')\n",
    "\n",
    "sel.xpath('/html').xpath('./body/div[2]')\n",
    "\n",
    "sel.xpath('/html').xpath('./body').xpath('./div[2]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs=sel.xpath('//div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "274"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1= 'https://en.wikipedia.org/wiki/List_of_data_breaches'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "html1 = requests.get( url1 ).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = Selector( text=html1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7551 elements in the HTML document.\n",
      "You have found:  7551\n"
     ]
    }
   ],
   "source": [
    "print( \"There are 7551 elements in the HTML document.\")\n",
    "print( \"You have found: \", len( sel.xpath('//*') ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#/ replace by > (except \u0000rst character) \n",
    "XPath: /html/body/div\n",
    "CSS Locator: html > body > div\n",
    "#// replaced by a blank space (except \u0000rst character)\n",
    "\n",
    "\n",
    "XPath: //div/span//p\n",
    "CSS Locator: div > span p\n",
    "#[N] replaced by :nth-of-type(N)\n",
    "XPath: //div/p[2]\n",
    "CSS Locator: div > p:nth-of-type(2)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the XPath string equivalent to the CSS Locator \n",
    "xpath = '/html/body/span[1]//a'\n",
    "\n",
    "# Create the CSS Locator string equivalent to the XPath\n",
    "css_locator = 'html > body > span:nth-of-type(1) a'\n",
    "\n",
    "# Create the XPath string equivalent to the CSS Locator \n",
    "xpath = '//div[@id=\"uid\"]/span//h4'\n",
    "\n",
    "# Create the CSS Locator string equivalent to the XPath\n",
    "css_locator = 'div#uid > span h4'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://towardsdatascience.com/data-analytics-with-python-by-web-scraping-illustration-with-cia-world-factbook-abbdaa687a84'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get( url ).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = Selector( text=html )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'how_many_elements' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f3d4fff890e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Print the number of selected elements.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhow_many_elements\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcss_locator\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'how_many_elements' is not defined"
     ]
    }
   ],
   "source": [
    "# Fill in the blank\n",
    "css_locator = 'div.course-block > a'\n",
    "\n",
    "# Print the number of selected elements.\n",
    "how_many_elements( css_locator )\n",
    "\n",
    "\n",
    "# Create the CSS Locator to all children of the element whose id is uid\n",
    "css_locator = \"#uid > *\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xpath\n",
    "<xpath-to-element>@attr-name\n",
    "xpath='//div[@id=\"uid\"]/a/@href'\n",
    "\n",
    "#CSS locator\n",
    "<css-to-element>::attr(attr-name)\n",
    "css='div#uid > a::attr(href)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Extraction\n",
    "\n",
    "\n",
    "<p id=\"p-example\">\n",
    "Hello world!\n",
    "Try <a href=\"http://www.datacamp.com\">DataCamp</a> today!\n",
    "</p>\n",
    "\n",
    "\n",
    "sel.xpath('//p[@id=\"p-example\"]/text()').extract() # result: ['\\n Hello world!\\n Try ', ' today!\\n']\n",
    "\n",
    " #with //\n",
    "sel.xpath('//p[@id=\"p-example\"]//text()').extract()\n",
    "# result: ['\\n Hello world!\\n Try ', 'DataCamp', ' today!\\n']\n",
    "\n",
    "\n",
    "#CSS Locator ::text\n",
    "sel.css('p#p-example::text').extract()\n",
    "# result: ['\\n Hello world!\\n Try ', ' today!\\n']\n",
    "\n",
    "sel.css('p#p-example ::text').extract()\n",
    "# result: ['\\n Hello world!\\n Try ', 'DataCamp', ' today!\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import Selector\n",
    "\n",
    "# Create a selector object from a secret website\n",
    "sel = Selector( text = html )\n",
    "\n",
    "# Select all hyperlinks of div elements belonging to class \"course-block\"\n",
    "course_as = sel.css( 'div.course-block > a' )\n",
    "\n",
    "# Selecting all href attributes chaining with css\n",
    "hrefs_from_css = course_as.css( '::attr(href)' )\n",
    "\n",
    "# Selecting all href attributes chaining with xpath\n",
    "hrefs_from_xpath = course_as.xpath( './@href' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "html= '\\n<html>\\n<body>\\n<div id=\"this-div\">\\n<p id=\"p1\" class=\"class-1\">This is not the element you are looking for</p>\\n<p id=\"p2\" class=\"class-12\">\\n<a href=\"https://www.google.com\">Google</a> is linked to here, but this isn\\'t the link you are looking for. \\n</p>\\n<p id=\"p3\" class=\"class-1 class-12\">\\nHere is the <a href=\"https://www.datacamp.com\" id=\"a-exercise\">DataCamp</a> link you want!\\n</p>\\n</div>\\n</body>\\n</html>\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will only be selecting the text within the element, which does not include the text in future generations of the element. We have created a function print_results for you to compare which elements your strings direct to.\n",
    "\n",
    "Assign to the variable xpath an XPath string directing to the text within the paragraph p element with id equal to p3, which does not include the text of future generations of this p element.\n",
    "Assign to the variable css_locator a CSS Locator string directing to this same text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "xpath='//p[@id=\"p3\"]/text()'\n",
    "\n",
    "# Create a CSS Locator string to the desired text.\n",
    "css_locator = 'p#p3::text'\n",
    "\n",
    "# Print the text from our selections\n",
    "print( xpath, css_locator )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will only be selecting the text within the element which includes all text within the future generations. We have created a function print_results for you to compare which elements your strings direct to.\n",
    "\n",
    "Assign to the variable xpath an XPath string directing to the text within the paragraph p element with id equal to p3, which includes the text of future generations of this p element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an XPath string to the desired text.\n",
    "xpath = '//p[@id=\"p3\"]//text()'\n",
    "\n",
    "# Create a CSS Locator string to the desired text.\n",
    "css_locator = 'p#p3 ::text'\n",
    "\n",
    "# Print the text from our selections\n",
    "print_results( xpath, css_locator )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reveal By Response\n",
    "We have pre-loaded a Response object, named response, with the content from a secret website. Your job is to figure out the URL and the title of the website using the response variable. You learned how to find the URL in the last lesson. To find the website title, what you need to know is:\n",
    "\n",
    "The title is the text from the title element\n",
    "The title element is a child of the head element, which is a child of the html root element.\n",
    "\n",
    "\n",
    "To note: the html root element only has one child head element, and the head element only has one child title element.\n",
    "    \n",
    "    Assign to the variable this_url the URL used to load the response variable.\n",
    "Assign to the variable this_title the title of the website used to load the response variable. Since we only want the text from the single element we will select, we use the extract_first() method to extract the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the URL to the website loaded in response\n",
    "this_url = response.url\n",
    "\n",
    "# Get the title of the website loaded in response\n",
    "this_title = response.xpath( '/html/head/title/text()' ).extract_first()\n",
    "\n",
    "# Print out our findings\n",
    "print_url_title( this_url, this_title )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "omething that we should emphasize at this point about the relationship between a Selector and Response objects is that both objects return a SelectorList when using the xpath or css methods to direct to elements. In this exercise, we'll prove it to you, by having you find all hyperlink elements belonging to the class course-block__link (notice the double underscore!) and looking at the object that is produced when doing so.\n",
    "\n",
    "Recall that to find an element by class, you can use a period (.). For example, div.class-2 selects all div elements belonging to class-2.\n",
    "\n",
    "We have pre-loaded both a Response object named response and a Selector object named sel with the content from the same \"secret\" website. Once you complete the task of creating a CSS Locator, you will compare both the output from response.css and selector.css to see that they are effectively the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CSS Locator string to the desired hyperlink elements\n",
    "css_locator = 'a.course-block__link'\n",
    "\n",
    "# Select the hyperlink elements from response and sel\n",
    "response_as = response.css( css_locator )\n",
    "sel_as = sel.css( css_locator )\n",
    "\n",
    "# Examine similarity\n",
    "nr = len( response_as )\n",
    "ns = len( sel_as )\n",
    "for i in range( min(nr, ns, 2) ):\n",
    "  print( \"Element %d from response: %s\" % (i+1, response_as[i]) )\n",
    "  print( \"Element %d from sel: %s\" % (i+1, sel_as[i]) )\n",
    "  print( \"\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.datacamp.com/courses/all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "html=requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-4ed6c85ec790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mthis_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'response' is not defined"
     ]
    }
   ],
   "source": [
    "this_url = response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SelectorList of the course titles\n",
    "crs_title_els = response.css( 'h4::text' )\n",
    "\n",
    "# Extract the course titles \n",
    "crs_titles = crs_title_els.extract()\n",
    "\n",
    "# Print out the course titles \n",
    "for el in crs_titles:\n",
    "  print( \">>\", el )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the scrapy library\n",
    "import scrapy\n",
    "\n",
    "# Create the Spider class\n",
    "class DCspider( scrapy.Spider ):\n",
    "  name = 'dcspider'\n",
    "  # start_requests method\n",
    "  def start_requests( self ):\n",
    "    yield scrapy.Request( url = url_short, callback = self.parse )\n",
    "  # parse method\n",
    "  def parse( self, response ):\n",
    "    # Create an extracted list of course author names\n",
    "    author_names = response.css('p.course-block__author-name::text').extract()\n",
    "    # Here we will just return the list of Authors\n",
    "    return author_names\n",
    "  \n",
    "# Inspect the spider\n",
    "inspect_spider( DCspider )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the scrapy library\n",
    "import scrapy\n",
    "\n",
    "# Create the Spider class\n",
    "class DCdescr( scrapy.Spider ):\n",
    "  name = 'dcdescr'\n",
    "  # start_requests method\n",
    "  def start_requests( self ):\n",
    "    yield scrapy.Request( url = url_short, callback = self.parse )\n",
    "  \n",
    "  # First parse method\n",
    "  def parse( self, response ):\n",
    "    links = response.css( 'div.course-block > a::attr(href)' ).extract()\n",
    "    # Follow each of the extracted links\n",
    "    for link in links:\n",
    "      yield response.follow( url = link, callback = self.parse_descr )\n",
    "      \n",
    "  # Second parsing method\n",
    "  def parse_descr( self, response ):\n",
    "    # Extract course description\n",
    "    course_descr = response.css( 'p.course__description::text' ).extract_first()\n",
    "    # For now, just yield the course description\n",
    "    yield course_descr\n",
    "\n",
    "\n",
    "# Inspect the spider\n",
    "inspect_spider( DCdescr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scrapy\n",
    "import scrapy\n",
    "\n",
    "# Import the CrawlerProcess: for running the spider\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "# Create the Spider class\n",
    "class DC_Chapter_Spider(scrapy.Spider):\n",
    "  name = \"dc_chapter_spider\"\n",
    "  # start_requests method\n",
    "  def start_requests(self):\n",
    "    yield scrapy.Request(url = url_short,\n",
    "                         callback = self.parse_front)\n",
    "  # First parsing method\n",
    "  def parse_front(self, response):\n",
    "    course_blocks = response.css('div.course-block')\n",
    "    course_links = course_blocks.xpath('./a/@href')\n",
    "    links_to_follow = course_links.extract()\n",
    "    for url in links_to_follow:\n",
    "      yield response.follow(url = url,\n",
    "                            callback = self.parse_pages)\n",
    "  # Second parsing method\n",
    "  def parse_pages(self, response):\n",
    "    crs_title = response.xpath('//h1[contains(@class,\"title\")]/text()')\n",
    "    crs_title_ext = crs_title.extract_first().strip()\n",
    "    ch_titles = response.css('h4.chapter__title::text')\n",
    "    ch_titles_ext = [t.strip() for t in ch_titles.extract()]\n",
    "    dc_dict[ crs_title_ext ] = ch_titles_ext\n",
    "\n",
    "# Initialize the dictionary **outside** of the Spider class\n",
    "dc_dict = dict()\n",
    "\n",
    "# Run the Spider\n",
    "process = CrawlerProcess()\n",
    "process.crawl(DC_Chapter_Spider)\n",
    "process.start()\n",
    "\n",
    "# Print a preview of courses\n",
    "previewCourses(dc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scrapy\n",
    "import scrapy\n",
    "\n",
    "# Import the CrawlerProcess: for running the spider\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "# Create the Spider class\n",
    "class DC_Description_Spider(scrapy.Spider):\n",
    "  name = \"dc_chapter_spider\"\n",
    "  # start_requests method\n",
    "  def start_requests(self):\n",
    "    yield scrapy.Request(url = url_short,\n",
    "                         callback = self.parse_front)\n",
    "  # First parsing method\n",
    "  def parse_front(self, response):\n",
    "    course_blocks = response.css('div.course-block')\n",
    "    course_links = course_blocks.xpath('./a/@href')\n",
    "    links_to_follow = course_links.extract()\n",
    "    for url in links_to_follow:\n",
    "      yield response.follow(url = url,\n",
    "                            callback = self.parse_pages)\n",
    "  # Second parsing method\n",
    "  def parse_pages(self, response):\n",
    "    # Create a SelectorList of the course titles text\n",
    "    crs_title = response.xpath('//h1[contains(@class,\"title\")]/text()')\n",
    "    # Extract the text and strip it clean\n",
    "    crs_title_ext = crs_title.extract_first().strip()\n",
    "    # Create a SelectorList of course descriptions text\n",
    "    crs_descr = response.css( 'p.course__description::text' )\n",
    "    # Extract the text and strip it clean\n",
    "    crs_descr_ext = crs_descr.extract_first().strip()\n",
    "    # Fill in the dictionary\n",
    "    dc_dict[crs_title_ext] = crs_descr_ext\n",
    "\n",
    "# Initialize the dictionary **outside** of the Spider class\n",
    "dc_dict = dict()\n",
    "\n",
    "# Run the Spider\n",
    "process = CrawlerProcess()\n",
    "process.crawl(DC_Description_Spider)\n",
    "process.start()\n",
    "\n",
    "# Print a preview of courses\n",
    "previewCourses(dc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse method\n",
    "def parse(self, response):\n",
    "  # Extracted course titles\n",
    "  crs_titles = response.xpath('//h4[contains(@class,\"block__title\")]/text()').extract()\n",
    "  # Extracted course descriptions\n",
    "  crs_descrs = response.xpath('//p[contains(@class,\"block__description\")]/text()').extract()\n",
    "  # Fill in the dictionary\n",
    "  for crs_title, crs_descr in zip(crs_titles, crs_descrs):\n",
    "    dc_dict[crs_title] = crs_descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
